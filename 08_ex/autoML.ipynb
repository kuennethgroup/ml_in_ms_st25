{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: Automated Machine Learning Tutorial\n",
    "\n",
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/kuennethgroup/ml_in_ms_wt24/blob/main/wt_25_ml_in_ms/08_ex/autoML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial introduces Automated Machine Learning (AutoML), a technique that automates the process of applying machine learning to real-world problems. AutoML handles tasks like feature selection, model selection, hyperparameter tuning, and model evaluation automatically.\n",
    "\n",
    "In this tutorial, we will:\n",
    "\n",
    "1. Learn about AutoML using the AutoGluon framework\n",
    "2. Work with a materials science dataset on polymer tendency to crystallize\n",
    "3. Compare different ML models automatically generated by AutoML\n",
    "4. Evaluate model performance using standard metrics\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We'll use a polymer dataset that contains molecular fingerprints and crystallization tendency values. The goal is to predict the tendency of a polymer to crystallize based on its molecular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (432, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>property</th>\n",
       "      <th>value</th>\n",
       "      <th>fingerprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[*]C[*]</td>\n",
       "      <td>Xc</td>\n",
       "      <td>47.80</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[*]CC([*])C</td>\n",
       "      <td>Xc</td>\n",
       "      <td>44.47</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[*]CC([*])CC</td>\n",
       "      <td>Xc</td>\n",
       "      <td>34.04</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[*]CC([*])CCC</td>\n",
       "      <td>Xc</td>\n",
       "      <td>20.01</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[*]CC([*])CC(C)C</td>\n",
       "      <td>Xc</td>\n",
       "      <td>21.64</td>\n",
       "      <td>[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>[*]C([*])(F)F</td>\n",
       "      <td>Xc</td>\n",
       "      <td>31.84</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>[*]C/C=C\\C[*]</td>\n",
       "      <td>Xc</td>\n",
       "      <td>25.58</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>[*]O[Si](C)(C)CCCC(=O)Oc1ccc(C=Nc2ccc(N=Cc3ccc...</td>\n",
       "      <td>Xc</td>\n",
       "      <td>29.05</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>[*]O[Si](C)(C)CCCC(=O)Oc1ccc(C=Nc2ccc(Cc3ccc(N...</td>\n",
       "      <td>Xc</td>\n",
       "      <td>21.74</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>[*]CCN(CCCCCCOc1ccc(C=Cc2ccc([N+](=O)[O-])cc2)...</td>\n",
       "      <td>Xc</td>\n",
       "      <td>7.55</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                smiles property  value  \\\n",
       "0                                              [*]C[*]       Xc  47.80   \n",
       "1                                          [*]CC([*])C       Xc  44.47   \n",
       "2                                         [*]CC([*])CC       Xc  34.04   \n",
       "3                                        [*]CC([*])CCC       Xc  20.01   \n",
       "4                                     [*]CC([*])CC(C)C       Xc  21.64   \n",
       "..                                                 ...      ...    ...   \n",
       "427                                      [*]C([*])(F)F       Xc  31.84   \n",
       "428                                      [*]C/C=C\\C[*]       Xc  25.58   \n",
       "429  [*]O[Si](C)(C)CCCC(=O)Oc1ccc(C=Nc2ccc(N=Cc3ccc...       Xc  29.05   \n",
       "430  [*]O[Si](C)(C)CCCC(=O)Oc1ccc(C=Nc2ccc(Cc3ccc(N...       Xc  21.74   \n",
       "431  [*]CCN(CCCCCCOc1ccc(C=Cc2ccc([N+](=O)[O-])cc2)...       Xc   7.55   \n",
       "\n",
       "                                           fingerprint  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "427  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "428  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "429  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "430  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "431  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, ...  \n",
       "\n",
       "[432 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries and load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the polymer crystallization dataset from GitHub\n",
    "df_ = pd.read_json(\n",
    "    \"https://raw.githubusercontent.com/kuennethgroup/materials_datasets/refs/heads/main/polymer_tendency_to_crystalize/polymers_tend_to_crystalize.json\"\n",
    ")\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "print(f\"Dataset shape: {df_.shape}\")\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Dataset\n",
    "\n",
    "The dataset contains the following columns:\n",
    "- `property`: The name of the property being measured (crystallization tendency)\n",
    "- `smiles`: The SMILES representation of the polymer structure\n",
    "- `value`: The numerical value representing crystallization tendency (our target variable)\n",
    "- `fingerprint`: Molecular fingerprints (numerical representations of molecular structures)\n",
    "\n",
    "Let's examine the data types and prepare our dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "smiles          object\n",
      "property        object\n",
      "value          float64\n",
      "fingerprint     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>fingerprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.80</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.47</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.04</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.01</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.64</td>\n",
       "      <td>[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value                                        fingerprint\n",
       "0  47.80  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1  44.47  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2  34.04  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3  20.01  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4  21.64  [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the data structure\n",
    "print(\"Data types:\")\n",
    "print(df_.dtypes)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "# We'll keep only the value (target) and fingerprint (features)\n",
    "df_prep = df_.drop(columns=[\"property\", \"smiles\"])\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The fingerprint column contains arrays of numerical values that represent molecular features. We need to convert these arrays into individual columns for our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset shape: (432, 2049)\n",
      "Number of features: 2048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  0  1  2  3  4  5  6  7  8  ...  2038  2039  2040  2041  2042  2043  \\\n",
       "0  47.80  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  44.47  0  1  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  34.04  1  1  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  20.01  0  1  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  21.64  0  2  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   2044  2045  2046  2047  \n",
       "0     0     0     0     0  \n",
       "1     0     0     0     0  \n",
       "2     0     0     0     0  \n",
       "3     0     0     0     0  \n",
       "4     0     0     0     0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the target variable\n",
    "df = df_prep[\"value\"].to_frame()\n",
    "\n",
    "# Convert the fingerprint arrays into individual columns\n",
    "# Each element in the fingerprint becomes a feature column\n",
    "df = pd.concat((df, pd.DataFrame(np.vstack(df_prep[\"fingerprint\"]))), axis=1)\n",
    "\n",
    "# Show the transformed dataset\n",
    "print(f\"Transformed dataset shape: {df.shape}\")\n",
    "print(f\"Number of features: {df.shape[1] - 1}\")  # -1 for the target column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Before building our models, we'll split the data into training and testing sets to properly evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: 432 samples\n",
      "Training set: 345 samples (79.9%)\n",
      "Testing set: 87 samples (20.1%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "# Using a fixed random_state for reproducibility\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Show the shapes of the original, training, and testing datasets\n",
    "print(f\"Total dataset: {len(df)} samples\")\n",
    "print(f\"Training set: {len(df_train)} samples ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Testing set: {len(df_test)} samples ({len(df_test)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML with AutoGluon\n",
    "\n",
    "AutoGluon is a powerful AutoML library that automatically trains and tunes a diverse set of machine learning models. It performs:\n",
    "\n",
    "1. **Feature engineering**: Automatically handling missing values, encoding categorical features, etc.\n",
    "2. **Model selection**: Testing various algorithms like Random Forest, XGBoost, Neural Networks, etc.\n",
    "3. **Hyperparameter tuning**: Finding optimal parameters for each model\n",
    "4. **Model ensembling**: Combining multiple models for better performance\n",
    "\n",
    "Let's prepare our data for AutoGluon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>57.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>28.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>79.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     value  0  1  2  3  4  5  6  7  8  ...  2038  2039  2040  2041  2042  \\\n",
       "132  57.62  0  1  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "231  28.37  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "31   21.61  0  1  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "84   79.99  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "296   0.37  0  1  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "\n",
       "     2043  2044  2045  2046  2047  \n",
       "132     0     0     0     0     0  \n",
       "231     0     0     0     0     0  \n",
       "31      0     0     0     0     0  \n",
       "84      0     0     0     0     0  \n",
       "296     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>72.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>53.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>38.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     value  0  1  2  3  4  5  6  7  8  ...  2038  2039  2040  2041  2042  \\\n",
       "424   8.38  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "75   72.53  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "180  53.05  0  0  0  0  0  0  0  0  1  ...     0     0     0     0     0   \n",
       "30   16.73  0  1  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "392  38.13  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "\n",
       "     2043  2044  2045  2046  2047  \n",
       "424     0     0     0     0     0  \n",
       "75      0     0     0     0     0  \n",
       "180     0     0     0     0     0  \n",
       "30      0     0     0     0     0  \n",
       "392     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# Convert our pandas DataFrames to AutoGluon's TabularDataset format\n",
    "train_data = TabularDataset(df_train)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "print(\"Training data:\")\n",
    "display(train_data.head())\n",
    "\n",
    "print(\"\\nTesting data:\")\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models with AutoML\n",
    "\n",
    "Now we'll use AutoGluon to automatically train and tune multiple machine learning models. We'll specify:\n",
    "\n",
    "- The target column (`label`)\n",
    "- The problem type (regression)\n",
    "- Time limit for training\n",
    "- Quality preset (determines how many models are tried and how extensively)\n",
    "\n",
    "The `fit()` method will handle the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250625_085548\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.8\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024\n",
      "CPU Count:          192\n",
      "Memory Avail:       901.78 GB / 1007.45 GB (89.5%)\n",
      "Disk Space Avail:   1513.42 GB / 7096.34 GB (21.3%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 20s of the 80s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-06-25 10:55:50,488\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/home/chris/courses/ml-in-ms-st25/08_ex/AutogluonModels/ag-20250625_085548/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Beginning AutoGluon training ... Time limit = 17s\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m AutoGluon will save models to \"/home/chris/courses/ml-in-ms-st25/08_ex/AutogluonModels/ag-20250625_085548/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Train Data Rows:    306\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Train Data Columns: 2048\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Label Column:       value\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tAvailable Memory:                    919505.16 MB\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tTrain Data (Original)  Memory Usage: 4.78 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\t\tNote: Converting 815 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tUseless Original Features (Count: 824): ['0', '3', '6', '10', '12', '15', '16', '18', '19', '20', '21', '23', '28', '35', '38', '40', '42', '46', '51', '56', '60', '61', '62', '63', '64', '65', '66', '71', '72', '77', '78', '82', '85', '86', '88', '89', '91', '92', '95', '96', '101', '103', '104', '107', '108', '111', '112', '113', '119', '120', '121', '123', '124', '127', '128', '129', '130', '134', '136', '137', '138', '141', '149', '150', '151', '153', '154', '155', '159', '160', '161', '165', '168', '169', '172', '177', '178', '179', '181', '182', '186', '189', '194', '198', '200', '205', '207', '208', '211', '215', '216', '218', '223', '224', '229', '238', '241', '242', '244', '250', '256', '257', '258', '259', '262', '263', '266', '267', '268', '272', '274', '277', '278', '280', '284', '286', '290', '291', '296', '297', '298', '299', '300', '309', '313', '320', '321', '324', '327', '328', '329', '331', '332', '334', '335', '337', '338', '344', '345', '346', '349', '351', '356', '360', '362', '365', '369', '370', '371', '380', '382', '384', '388', '390', '394', '395', '396', '397', '400', '402', '403', '404', '405', '409', '410', '412', '413', '414', '415', '416', '417', '418', '419', '421', '425', '426', '427', '431', '433', '434', '435', '439', '441', '442', '446', '447', '448', '450', '452', '454', '455', '456', '457', '458', '459', '462', '464', '465', '468', '470', '474', '475', '479', '491', '492', '493', '496', '500', '501', '505', '506', '508', '513', '514', '517', '520', '523', '524', '528', '529', '530', '531', '532', '533', '535', '536', '542', '543', '546', '550', '551', '552', '554', '556', '557', '558', '560', '565', '566', '571', '575', '576', '586', '593', '595', '596', '601', '602', '610', '611', '613', '614', '616', '623', '624', '627', '630', '631', '634', '635', '638', '641', '644', '646', '647', '651', '652', '657', '661', '665', '669', '672', '678', '688', '689', '690', '696', '697', '700', '702', '704', '705', '708', '709', '712', '716', '717', '720', '722', '724', '727', '729', '730', '731', '732', '735', '737', '738', '740', '747', '748', '752', '754', '756', '757', '758', '762', '764', '765', '768', '771', '773', '777', '778', '780', '782', '786', '788', '791', '792', '793', '795', '800', '805', '808', '809', '813', '815', '816', '817', '818', '819', '821', '833', '837', '839', '840', '842', '844', '847', '849', '852', '855', '861', '869', '872', '873', '874', '876', '884', '885', '887', '889', '890', '894', '899', '902', '903', '911', '913', '917', '919', '920', '922', '927', '928', '930', '938', '939', '943', '944', '947', '949', '950', '952', '955', '958', '962', '963', '965', '970', '971', '973', '974', '976', '977', '978', '980', '982', '985', '988', '989', '990', '992', '993', '997', '1000', '1001', '1002', '1005', '1011', '1016', '1018', '1021', '1022', '1025', '1026', '1029', '1030', '1033', '1035', '1037', '1040', '1041', '1046', '1047', '1053', '1058', '1059', '1065', '1072', '1073', '1075', '1078', '1079', '1086', '1092', '1093', '1094', '1097', '1099', '1101', '1102', '1104', '1105', '1106', '1112', '1115', '1121', '1122', '1124', '1129', '1130', '1131', '1133', '1134', '1136', '1137', '1139', '1141', '1148', '1149', '1150', '1153', '1154', '1159', '1166', '1169', '1170', '1171', '1177', '1181', '1183', '1186', '1190', '1192', '1193', '1194', '1198', '1202', '1204', '1206', '1207', '1211', '1212', '1214', '1216', '1217', '1218', '1220', '1226', '1228', '1230', '1231', '1233', '1236', '1237', '1241', '1242', '1246', '1247', '1250', '1253', '1255', '1256', '1257', '1258', '1259', '1260', '1261', '1264', '1265', '1268', '1270', '1271', '1272', '1273', '1275', '1279', '1281', '1284', '1285', '1288', '1291', '1293', '1294', '1295', '1298', '1300', '1302', '1304', '1305', '1307', '1311', '1312', '1315', '1316', '1320', '1329', '1330', '1334', '1336', '1337', '1338', '1339', '1340', '1342', '1346', '1351', '1354', '1355', '1358', '1359', '1361', '1363', '1367', '1368', '1369', '1371', '1373', '1376', '1377', '1381', '1387', '1388', '1389', '1390', '1395', '1396', '1397', '1401', '1402', '1403', '1404', '1405', '1406', '1407', '1408', '1410', '1412', '1414', '1418', '1423', '1426', '1428', '1429', '1431', '1433', '1434', '1437', '1438', '1443', '1447', '1448', '1449', '1451', '1455', '1458', '1461', '1465', '1468', '1469', '1474', '1475', '1477', '1478', '1483', '1484', '1486', '1488', '1491', '1496', '1497', '1498', '1500', '1504', '1505', '1509', '1510', '1511', '1512', '1519', '1521', '1526', '1528', '1529', '1532', '1535', '1537', '1538', '1539', '1540', '1541', '1543', '1545', '1547', '1548', '1549', '1550', '1552', '1554', '1556', '1558', '1560', '1561', '1562', '1563', '1566', '1567', '1568', '1570', '1572', '1574', '1577', '1578', '1583', '1584', '1591', '1593', '1595', '1596', '1597', '1598', '1600', '1601', '1613', '1615', '1620', '1621', '1623', '1626', '1628', '1629', '1630', '1631', '1635', '1636', '1637', '1638', '1640', '1642', '1644', '1648', '1651', '1653', '1657', '1662', '1663', '1664', '1667', '1670', '1675', '1677', '1678', '1680', '1681', '1682', '1684', '1687', '1689', '1690', '1696', '1698', '1701', '1702', '1704', '1706', '1707', '1709', '1711', '1716', '1723', '1724', '1725', '1730', '1732', '1733', '1736', '1739', '1741', '1742', '1744', '1748', '1751', '1752', '1756', '1759', '1761', '1763', '1765', '1767', '1771', '1776', '1780', '1783', '1784', '1787', '1789', '1790', '1792', '1794', '1797', '1801', '1808', '1813', '1815', '1817', '1818', '1820', '1828', '1832', '1833', '1835', '1836', '1837', '1838', '1841', '1852', '1859', '1861', '1864', '1866', '1869', '1871', '1872', '1874', '1875', '1879', '1880', '1881', '1890', '1891', '1892', '1893', '1897', '1902', '1903', '1906', '1907', '1909', '1912', '1914', '1918', '1921', '1927', '1931', '1933', '1936', '1938', '1943', '1944', '1946', '1949', '1953', '1954', '1957', '1961', '1966', '1967', '1969', '1972', '1973', '1974', '1976', '1977', '1980', '1981', '1986', '1987', '1994', '1997', '1998', '1999', '2005', '2007', '2008', '2010', '2011', '2012', '2014', '2015', '2017', '2018', '2024', '2025', '2028', '2029', '2030', '2037', '2038', '2040', '2042', '2044', '2046']\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tUnused Original Features (Count: 382): ['30', '47', '67', '75', '146', '157', '163', '185', '199', '201', '204', '234', '246', '254', '255', '260', '265', '271', '285', '301', '304', '305', '306', '307', '315', '317', '318', '341', '347', '353', '364', '372', '377', '381', '387', '406', '411', '428', '445', '451', '472', '485', '490', '498', '499', '502', '509', '512', '516', '525', '527', '537', '538', '544', '549', '561', '563', '567', '568', '582', '585', '599', '600', '603', '629', '633', '643', '648', '649', '653', '654', '655', '658', '659', '663', '666', '675', '681', '701', '707', '719', '723', '726', '741', '750', '761', '767', '772', '774', '776', '779', '796', '797', '798', '802', '810', '811', '812', '814', '822', '825', '828', '838', '845', '853', '860', '863', '871', '877', '880', '895', '897', '904', '906', '914', '916', '925', '936', '941', '946', '954', '960', '966', '968', '979', '984', '986', '1004', '1020', '1027', '1032', '1042', '1048', '1049', '1050', '1051', '1056', '1060', '1061', '1062', '1067', '1068', '1069', '1076', '1080', '1082', '1083', '1084', '1085', '1089', '1091', '1095', '1098', '1100', '1108', '1109', '1111', '1118', '1123', '1125', '1126', '1127', '1128', '1138', '1140', '1142', '1155', '1165', '1167', '1168', '1172', '1173', '1175', '1184', '1187', '1189', '1195', '1197', '1203', '1208', '1210', '1215', '1219', '1222', '1223', '1225', '1235', '1239', '1245', '1248', '1262', '1266', '1278', '1289', '1296', '1306', '1309', '1310', '1322', '1323', '1324', '1331', '1332', '1333', '1335', '1347', '1348', '1353', '1357', '1360', '1362', '1372', '1374', '1378', '1379', '1383', '1393', '1400', '1409', '1411', '1413', '1415', '1416', '1421', '1424', '1439', '1445', '1457', '1463', '1464', '1467', '1470', '1472', '1479', '1481', '1487', '1489', '1490', '1492', '1499', '1503', '1506', '1508', '1514', '1515', '1516', '1517', '1523', '1527', '1530', '1531', '1533', '1534', '1542', '1553', '1557', '1559', '1569', '1573', '1576', '1580', '1585', '1604', '1605', '1606', '1607', '1608', '1609', '1611', '1614', '1616', '1618', '1619', '1624', '1625', '1627', '1633', '1634', '1639', '1646', '1650', '1654', '1656', '1659', '1672', '1674', '1685', '1692', '1708', '1710', '1712', '1713', '1720', '1721', '1726', '1735', '1738', '1745', '1746', '1749', '1760', '1762', '1764', '1773', '1774', '1778', '1779', '1781', '1782', '1785', '1786', '1791', '1793', '1796', '1802', '1803', '1805', '1807', '1812', '1814', '1819', '1827', '1829', '1834', '1844', '1845', '1848', '1850', '1858', '1860', '1862', '1863', '1865', '1867', '1868', '1870', '1877', '1883', '1889', '1894', '1898', '1899', '1900', '1901', '1904', '1905', '1908', '1913', '1919', '1922', '1923', '1925', '1929', '1932', '1935', '1937', '1939', '1941', '1950', '1955', '1960', '1965', '1968', '1971', '1975', '1983', '1984', '1993', '2001', '2002', '2003', '2006', '2013', '2021', '2022', '2026', '2031', '2032', '2034', '2039', '2043', '2045']\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\t('int', []) : 382 | ['30', '47', '67', '75', '146', ...]\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\t('int', []) : 842 | ['1', '2', '4', '5', '7', ...]\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\t('int', [])       : 389 | ['1', '8', '9', '11', '13', ...]\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t\t('int', ['bool']) : 453 | ['2', '4', '5', '7', '14', ...]\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t2.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t842 features in original data used to generate 842 features in processed data.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Data preprocessing and feature engineering runtime = 2.29s ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'NN_TORCH': [{}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'CAT': [{}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'XGB': [{}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'FASTAI': [{}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9.55s of the 14.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=8497)\u001b[0m [1000]\tvalid_set's rmse: 13.4164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-18.6573\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t1.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 6.90s of the 11.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-19.1182\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 4.42s of the 9.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-19.357\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 3.55s of the 8.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=50826)\u001b[0m \tRan out of time, early stopping on iteration 698.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-19.1311\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t2.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 14.32s of the 3.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.591, 'CatBoost_BAG_L1': 0.273, 'RandomForestMSE_BAG_L1': 0.136}\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-18.4299\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3.84s of the 3.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=95055)\u001b[0m [1000]\tvalid_set's rmse: 18.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-18.7711\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t1.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 0.89s of the 0.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=111584)\u001b[0m \tRan out of time, early stopping on iteration 656. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=111584)\u001b[0m \t[651]\tvalid_set's rmse: 18.4613\n",
      "\u001b[36m(_ray_fit pid=50673)\u001b[0m \tRan out of time, early stopping on iteration 650.\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-18.8231\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 14.32s of the -1.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.591, 'CatBoost_BAG_L1': 0.273, 'RandomForestMSE_BAG_L1': 0.136}\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t-18.4299\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m AutoGluon training complete, total runtime = 18.18s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 136.7 rows/s (39 batch size)\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t2.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.591, 'CatBoost_BAG_L1': 0.273, 'RandomForestMSE_BAG_L1': 0.136}\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_ray_fit pid=111588)\u001b[0m \tRan out of time, early stopping on iteration 358. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=111588)\u001b[0m \t[63]\tvalid_set's rmse: 15.5229\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.591, 'CatBoost_BAG_L1': 0.273, 'RandomForestMSE_BAG_L1': 0.136}\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Refit complete, total runtime = 5.97s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chris/courses/ml-in-ms-st25/08_ex/AutogluonModels/ag-20250625_085548/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=4156447)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                         model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       LightGBMXT_BAG_L2_FULL     -13.697031 -18.771087  root_mean_squared_error        0.134895            NaN  5.065252                 0.025582                     NaN           0.546882            2       True          6\n",
      "1       LightGBMXT_BAG_L1_FULL     -14.094939 -18.657271  root_mean_squared_error        0.019588            NaN  0.945633                 0.019588                     NaN           0.945633            1       True          1\n",
      "2         LightGBM_BAG_L1_FULL     -14.178505 -19.118233  root_mean_squared_error        0.023288            NaN  0.585627                 0.023288                     NaN           0.585627            1       True          2\n",
      "3     WeightedEnsemble_L3_FULL     -14.217708 -18.429853  root_mean_squared_error        0.111039            NaN  4.524538                 0.001727                     NaN           0.006168            3       True          8\n",
      "4     WeightedEnsemble_L2_FULL     -14.217708 -18.429853  root_mean_squared_error        0.111724            NaN  4.524566                 0.002412                     NaN           0.006196            2       True          5\n",
      "5         CatBoost_BAG_L1_FULL     -14.671804 -19.131090  root_mean_squared_error        0.026836            NaN  2.921215                 0.026836                     NaN           2.921215            1       True          4\n",
      "6         LightGBM_BAG_L2_FULL     -15.507024 -18.823149  root_mean_squared_error        0.129684            NaN  4.899120                 0.020372                     NaN           0.380749            2       True          7\n",
      "7  RandomForestMSE_BAG_L1_FULL     -16.038908 -19.356983  root_mean_squared_error        0.062889       0.106011  0.651522                 0.062889                0.106011           0.651522            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t29s\t = DyStack   runtime |\t51s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 51s\n",
      "AutoGluon will save models to \"/home/chris/courses/ml-in-ms-st25/08_ex/AutogluonModels/ag-20250625_085548\"\n",
      "Train Data Rows:    345\n",
      "Train Data Columns: 2048\n",
      "Label Column:       value\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    919185.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.39 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 843 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 780): ['3', '6', '10', '15', '16', '18', '19', '21', '23', '28', '35', '38', '40', '42', '46', '51', '56', '60', '62', '63', '64', '65', '66', '71', '72', '77', '78', '82', '85', '86', '88', '89', '91', '92', '95', '96', '101', '103', '104', '107', '108', '111', '112', '113', '119', '120', '121', '123', '124', '127', '128', '129', '130', '134', '136', '137', '138', '141', '149', '150', '151', '153', '154', '155', '159', '160', '161', '168', '169', '172', '177', '178', '179', '181', '182', '186', '189', '194', '198', '200', '205', '207', '211', '215', '216', '218', '223', '224', '229', '238', '241', '242', '244', '250', '256', '258', '259', '263', '266', '268', '272', '274', '277', '278', '280', '284', '286', '290', '291', '296', '297', '298', '299', '300', '309', '313', '321', '327', '328', '329', '331', '332', '334', '335', '337', '338', '344', '345', '346', '349', '351', '356', '360', '362', '365', '369', '370', '371', '380', '382', '384', '388', '390', '394', '395', '396', '397', '400', '402', '403', '404', '405', '409', '410', '412', '413', '414', '415', '416', '417', '418', '419', '421', '425', '426', '427', '431', '433', '434', '435', '439', '441', '442', '446', '447', '448', '450', '452', '454', '455', '456', '457', '458', '459', '462', '464', '465', '468', '470', '474', '475', '479', '491', '492', '493', '496', '500', '501', '505', '506', '508', '513', '514', '517', '520', '523', '524', '528', '529', '531', '532', '533', '535', '536', '542', '543', '546', '550', '551', '552', '554', '556', '557', '560', '565', '566', '571', '575', '576', '586', '593', '595', '596', '601', '602', '610', '611', '613', '614', '616', '623', '624', '627', '630', '631', '634', '635', '641', '646', '647', '651', '661', '665', '669', '672', '678', '688', '689', '690', '696', '697', '700', '702', '704', '705', '708', '709', '712', '716', '717', '720', '722', '724', '727', '730', '731', '732', '735', '737', '738', '740', '747', '748', '752', '754', '756', '757', '758', '762', '765', '768', '771', '773', '777', '778', '780', '782', '786', '788', '791', '792', '793', '795', '800', '805', '808', '809', '813', '815', '816', '817', '818', '819', '821', '833', '837', '840', '842', '844', '847', '849', '852', '855', '861', '869', '872', '873', '874', '876', '884', '885', '887', '889', '890', '894', '899', '902', '903', '911', '913', '917', '919', '920', '922', '927', '928', '930', '938', '939', '943', '944', '947', '949', '950', '952', '955', '958', '962', '963', '965', '970', '971', '973', '974', '976', '977', '978', '980', '982', '985', '988', '989', '990', '992', '997', '1000', '1001', '1002', '1005', '1011', '1016', '1018', '1021', '1022', '1025', '1026', '1029', '1030', '1033', '1035', '1037', '1040', '1041', '1046', '1047', '1053', '1058', '1059', '1065', '1072', '1073', '1075', '1078', '1079', '1086', '1092', '1093', '1094', '1097', '1099', '1101', '1102', '1104', '1105', '1106', '1112', '1115', '1121', '1122', '1124', '1129', '1130', '1131', '1133', '1134', '1136', '1137', '1139', '1141', '1148', '1149', '1150', '1153', '1154', '1159', '1166', '1169', '1170', '1171', '1177', '1181', '1183', '1186', '1190', '1192', '1194', '1198', '1202', '1204', '1206', '1207', '1211', '1212', '1214', '1216', '1217', '1218', '1220', '1226', '1230', '1231', '1233', '1236', '1237', '1241', '1242', '1246', '1247', '1250', '1253', '1256', '1257', '1258', '1259', '1260', '1261', '1264', '1265', '1268', '1270', '1272', '1273', '1275', '1279', '1281', '1284', '1285', '1288', '1291', '1293', '1294', '1295', '1298', '1300', '1302', '1304', '1305', '1307', '1311', '1312', '1315', '1316', '1320', '1329', '1334', '1336', '1337', '1338', '1339', '1340', '1342', '1346', '1351', '1354', '1355', '1358', '1359', '1361', '1367', '1368', '1369', '1371', '1373', '1376', '1377', '1381', '1387', '1388', '1389', '1390', '1395', '1396', '1397', '1401', '1402', '1403', '1404', '1405', '1406', '1407', '1408', '1410', '1412', '1414', '1418', '1423', '1426', '1428', '1429', '1431', '1433', '1434', '1437', '1438', '1443', '1447', '1448', '1449', '1451', '1458', '1461', '1465', '1468', '1469', '1474', '1475', '1477', '1478', '1483', '1484', '1486', '1488', '1491', '1496', '1497', '1498', '1500', '1504', '1505', '1509', '1510', '1511', '1519', '1526', '1528', '1529', '1532', '1535', '1537', '1538', '1541', '1543', '1547', '1548', '1549', '1550', '1552', '1554', '1556', '1558', '1560', '1561', '1562', '1563', '1566', '1567', '1568', '1570', '1572', '1574', '1577', '1578', '1583', '1584', '1591', '1593', '1595', '1596', '1598', '1600', '1601', '1613', '1615', '1620', '1621', '1623', '1626', '1628', '1629', '1631', '1635', '1636', '1637', '1638', '1640', '1642', '1644', '1648', '1651', '1657', '1662', '1663', '1664', '1667', '1670', '1675', '1677', '1678', '1680', '1681', '1682', '1684', '1687', '1689', '1690', '1696', '1698', '1701', '1702', '1704', '1706', '1707', '1709', '1711', '1716', '1723', '1724', '1730', '1732', '1736', '1739', '1742', '1744', '1748', '1752', '1756', '1759', '1761', '1763', '1765', '1767', '1771', '1776', '1780', '1783', '1784', '1787', '1789', '1790', '1792', '1794', '1797', '1801', '1808', '1813', '1815', '1817', '1818', '1820', '1828', '1832', '1833', '1835', '1836', '1837', '1838', '1841', '1852', '1859', '1861', '1864', '1866', '1869', '1871', '1872', '1874', '1875', '1879', '1880', '1881', '1890', '1891', '1892', '1893', '1897', '1902', '1903', '1906', '1907', '1909', '1914', '1918', '1921', '1927', '1931', '1933', '1936', '1938', '1943', '1944', '1946', '1949', '1953', '1954', '1957', '1966', '1967', '1969', '1972', '1973', '1974', '1976', '1977', '1980', '1981', '1986', '1987', '1994', '1998', '1999', '2005', '2007', '2010', '2011', '2012', '2014', '2015', '2017', '2018', '2024', '2025', '2028', '2029', '2030', '2037', '2038', '2040', '2042', '2044', '2046']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 386): ['47', '61', '67', '75', '146', '157', '163', '185', '199', '201', '204', '208', '234', '246', '254', '255', '257', '260', '262', '265', '271', '285', '304', '305', '306', '315', '317', '318', '320', '324', '341', '353', '364', '372', '377', '381', '406', '428', '445', '451', '472', '485', '490', '498', '499', '502', '509', '512', '516', '525', '527', '537', '538', '549', '558', '561', '563', '567', '568', '582', '585', '599', '600', '603', '629', '633', '638', '643', '644', '648', '649', '653', '654', '655', '657', '658', '659', '663', '666', '675', '681', '701', '707', '723', '726', '729', '741', '750', '764', '767', '772', '774', '776', '779', '796', '797', '798', '802', '810', '811', '812', '822', '825', '828', '838', '839', '845', '853', '860', '863', '871', '877', '880', '895', '897', '904', '906', '914', '916', '925', '936', '941', '946', '960', '966', '968', '979', '984', '986', '993', '1004', '1020', '1027', '1032', '1042', '1048', '1049', '1050', '1051', '1060', '1061', '1062', '1067', '1068', '1069', '1080', '1082', '1084', '1085', '1089', '1091', '1095', '1098', '1100', '1108', '1109', '1111', '1118', '1123', '1125', '1126', '1127', '1140', '1142', '1155', '1165', '1167', '1168', '1172', '1173', '1175', '1184', '1187', '1189', '1193', '1195', '1197', '1203', '1208', '1210', '1215', '1219', '1222', '1223', '1225', '1228', '1235', '1239', '1245', '1248', '1266', '1271', '1278', '1289', '1296', '1306', '1310', '1322', '1324', '1330', '1331', '1332', '1333', '1335', '1347', '1348', '1353', '1360', '1362', '1363', '1372', '1374', '1378', '1379', '1383', '1393', '1400', '1409', '1411', '1413', '1416', '1421', '1424', '1439', '1445', '1455', '1457', '1463', '1464', '1467', '1470', '1472', '1479', '1481', '1487', '1489', '1490', '1492', '1503', '1506', '1508', '1512', '1514', '1515', '1516', '1517', '1521', '1523', '1527', '1530', '1531', '1534', '1540', '1542', '1545', '1553', '1557', '1559', '1569', '1573', '1576', '1580', '1585', '1597', '1604', '1605', '1606', '1607', '1608', '1609', '1611', '1614', '1618', '1619', '1624', '1625', '1627', '1630', '1633', '1634', '1639', '1646', '1650', '1653', '1654', '1656', '1659', '1672', '1674', '1685', '1692', '1708', '1710', '1712', '1713', '1720', '1721', '1725', '1726', '1733', '1735', '1738', '1741', '1745', '1746', '1751', '1760', '1762', '1764', '1773', '1778', '1779', '1781', '1782', '1786', '1791', '1793', '1796', '1803', '1805', '1807', '1812', '1814', '1819', '1827', '1829', '1834', '1844', '1845', '1848', '1850', '1858', '1860', '1862', '1863', '1865', '1867', '1868', '1870', '1877', '1883', '1894', '1898', '1899', '1900', '1901', '1904', '1905', '1908', '1912', '1913', '1919', '1922', '1923', '1925', '1929', '1932', '1935', '1937', '1939', '1941', '1950', '1955', '1960', '1961', '1965', '1968', '1971', '1975', '1983', '1993', '1997', '2001', '2003', '2006', '2008', '2013', '2021', '2022', '2026', '2031', '2032', '2034', '2039', '2043', '2045']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 386 | ['47', '61', '67', '75', '146', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 882 | ['0', '1', '2', '4', '5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 409 | ['1', '2', '8', '9', '11', ...]\n",
      "\t\t('int', ['bool']) : 473 | ['0', '4', '5', '7', '12', ...]\n",
      "\t2.8s = Fit runtime\n",
      "\t882 features in original data used to generate 882 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.23 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.83s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 31.97s of the 47.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-18.1373\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.43s of the 45.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-18.6287\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 26.87s of the 42.87s of remaining time.\n",
      "\t-19.0275\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 26.00s of the 41.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.04%)\n",
      "\t-18.315\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.78s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 20.62s of the 36.61s of remaining time.\n",
      "\t-19.016\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 19.63s of the 35.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.00%)\n",
      "\t-19.2856\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.77s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 14.28s of the 30.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.04%)\n",
      "\t-18.5863\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 11.35s of the 27.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.00%)\n",
      "\t-17.5922\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.54s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 47.96s of the 15.11s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.538, 'LightGBMXT_BAG_L1': 0.308, 'CatBoost_BAG_L1': 0.077, 'XGBoost_BAG_L1': 0.077}\n",
      "\t-17.1752\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 15.06s of the 15.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-17.1289\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 8.60s of the 8.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-17.6774\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 6.21s of the 6.21s of remaining time.\n",
      "\t-18.0499\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 5.37s of the 5.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.04%)\n",
      "\t-17.3929\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1.15s of the 1.15s of remaining time.\n",
      "\t-17.507\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 47.96s of the 0.36s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.522, 'NeuralNetTorch_BAG_L1': 0.304, 'ExtraTreesMSE_BAG_L2': 0.13, 'CatBoost_BAG_L2': 0.043}\n",
      "\t-16.9282\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 50.49s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 23.0 rows/s (44 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.9s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.61s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t1.07s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t0.98s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.5s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t3.5s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.538, 'LightGBMXT_BAG_L1': 0.308, 'CatBoost_BAG_L1': 0.077, 'XGBoost_BAG_L1': 0.077}\n",
      "\t0.01s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t1.41s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.39s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.74s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.522, 'NeuralNetTorch_BAG_L1': 0.304, 'ExtraTreesMSE_BAG_L2': 0.13, 'CatBoost_BAG_L2': 0.043}\n",
      "\t0.01s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 13.21s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chris/courses/ml-in-ms-st25/08_ex/AutogluonModels/ag-20250625_085548\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train models using AutoGluon\n",
    "predictor = TabularPredictor(\n",
    "    label=\"value\",  # Our target column\n",
    "    problem_type=\"regression\",  # We're predicting a continuous value\n",
    ").fit(\n",
    "    train_data,\n",
    "    time_limit=80,  # Limit training time to 80 seconds\n",
    "    presets=\"good_quality\",  # Use high-quality preset for better models\n",
    ")\n",
    "\n",
    "# Note: The \"good_quality\" preset enables more models and more extensive hyperparameter tuning\n",
    "# Other options include: \"best_quality\", \"good_quality\", \"medium_quality\", etc.\n",
    "# See: https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "\n",
    "Now that we've trained our models, let's evaluate their performance on the test set. We'll:\n",
    "\n",
    "1. Generate predictions on our test data\n",
    "2. Calculate common regression metrics (RMSE and RÂ²)\n",
    "3. Visualize actual vs. predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/courses/ml-in-ms-st25/.venv/lib/python3.12/site-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² Score: 0.3859 (higher is better, 1.0 is perfect)\n",
      "RMSE: 19.3416 (lower is better, 0.0 is perfect)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Create a visualization of actual vs. predicted values\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_pred = predictor.predict(test_data.drop(columns=[\"value\"]))\n",
    "y_true = test_data[\"value\"]\n",
    "\n",
    "# Calculate performance metrics\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Plot actual vs. predicted values\n",
    "ax.scatter(y_pred, y_true, alpha=0.5)\n",
    "ax.plot([0, 100], [0, 100], \"k--\", label=\"Perfect prediction\")\n",
    "\n",
    "# Add metric annotations\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.9,\n",
    "    f\"RÂ² = {r2:.3f}\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8),\n",
    ")\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.85,\n",
    "    f\"RMSE = {rmse:.3f}\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8),\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_title(\"Test Set: Predicted vs. Actual Crystallization Tendency\", fontsize=14)\n",
    "ax.set_ylabel(\"Actual Values\", fontsize=12)\n",
    "ax.set_xlabel(\"Predicted Values\", fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"RÂ² Score: {r2:.4f} (higher is better, 1.0 is perfect)\")\n",
    "print(f\"RMSE: {rmse:.4f} (lower is better, 0.0 is perfect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Model Leaderboard\n",
    "\n",
    "One of the major benefits of AutoML is that it tries multiple models and ranks them by performance. Let's examine the leaderboard to see which models performed best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/courses/ml-in-ms-st25/.venv/lib/python3.12/site-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>-18.349798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.976656</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>-18.646686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613156</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613156</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>-18.655791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073183</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073183</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2_FULL</td>\n",
       "      <td>-18.827901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.427677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.061599</td>\n",
       "      <td>0.027284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735244</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1_FULL</td>\n",
       "      <td>-18.832202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.057180</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0.745788</td>\n",
       "      <td>0.057180</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0.745788</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-18.832202</td>\n",
       "      <td>-19.015966</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.061879</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0.745788</td>\n",
       "      <td>0.061879</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0.745788</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2_FULL</td>\n",
       "      <td>-18.876572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.466024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.879183</td>\n",
       "      <td>0.065631</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.552829</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-18.984090</td>\n",
       "      <td>-19.027544</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.057920</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>0.634167</td>\n",
       "      <td>0.057920</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>0.634167</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestMSE_BAG_L1_FULL</td>\n",
       "      <td>-18.984090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>0.634167</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>0.634167</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>-19.174944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.035028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>0.035028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L3_FULL</td>\n",
       "      <td>-19.341571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.520418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.033476</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_BAG_L2_FULL</td>\n",
       "      <td>-19.590850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.420932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.716364</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.390009</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>-19.840232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.155318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.499712</td>\n",
       "      <td>0.155318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.499712</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>-19.937957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.042751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497625</td>\n",
       "      <td>0.042751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497625</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestMSE_BAG_L2_FULL</td>\n",
       "      <td>-20.313934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.467423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.937135</td>\n",
       "      <td>0.067029</td>\n",
       "      <td>0.113872</td>\n",
       "      <td>0.610780</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBMXT_BAG_L2_FULL</td>\n",
       "      <td>-20.385369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.425257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.737270</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.410915</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
       "      <td>-20.427177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.024496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979337</td>\n",
       "      <td>0.024496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979337</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.928197</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.196870</td>\n",
       "      <td>29.720611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.128938</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.841475</td>\n",
       "      <td>26.576901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046031</td>\n",
       "      <td>4.835958</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.175240</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.499218</td>\n",
       "      <td>16.601287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.392871</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.051022</td>\n",
       "      <td>24.323691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255578</td>\n",
       "      <td>2.582748</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.506980</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.895018</td>\n",
       "      <td>22.293772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.552829</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.592214</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.163003</td>\n",
       "      <td>10.544702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.163003</td>\n",
       "      <td>10.544702</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.677431</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.834052</td>\n",
       "      <td>22.562593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038608</td>\n",
       "      <td>0.821650</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.049925</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.909316</td>\n",
       "      <td>22.351723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113872</td>\n",
       "      <td>0.610780</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.137322</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.943573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.943573</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.314984</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258069</td>\n",
       "      <td>3.784321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258069</td>\n",
       "      <td>3.784321</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.586261</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045983</td>\n",
       "      <td>1.319098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045983</td>\n",
       "      <td>1.319098</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.628670</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.984569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.984569</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.285642</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074093</td>\n",
       "      <td>3.769294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074093</td>\n",
       "      <td>3.769294</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_test  score_val  \\\n",
       "0      WeightedEnsemble_L2_FULL  -18.349798        NaN   \n",
       "1          LightGBM_BAG_L1_FULL  -18.646686        NaN   \n",
       "2          CatBoost_BAG_L1_FULL  -18.655791        NaN   \n",
       "3          CatBoost_BAG_L2_FULL  -18.827901        NaN   \n",
       "4     ExtraTreesMSE_BAG_L1_FULL  -18.832202        NaN   \n",
       "5          ExtraTreesMSE_BAG_L1  -18.832202 -19.015966   \n",
       "6     ExtraTreesMSE_BAG_L2_FULL  -18.876572        NaN   \n",
       "7        RandomForestMSE_BAG_L1  -18.984090 -19.027544   \n",
       "8   RandomForestMSE_BAG_L1_FULL  -18.984090        NaN   \n",
       "9        LightGBMXT_BAG_L1_FULL  -19.174944        NaN   \n",
       "10     WeightedEnsemble_L3_FULL  -19.341571        NaN   \n",
       "11         LightGBM_BAG_L2_FULL  -19.590850        NaN   \n",
       "12   NeuralNetTorch_BAG_L1_FULL  -19.840232        NaN   \n",
       "13          XGBoost_BAG_L1_FULL  -19.937957        NaN   \n",
       "14  RandomForestMSE_BAG_L2_FULL  -20.313934        NaN   \n",
       "15       LightGBMXT_BAG_L2_FULL  -20.385369        NaN   \n",
       "16  NeuralNetFastAI_BAG_L1_FULL  -20.427177        NaN   \n",
       "17          WeightedEnsemble_L3         NaN -16.928197   \n",
       "18            LightGBMXT_BAG_L2         NaN -17.128938   \n",
       "19          WeightedEnsemble_L2         NaN -17.175240   \n",
       "20              CatBoost_BAG_L2         NaN -17.392871   \n",
       "21         ExtraTreesMSE_BAG_L2         NaN -17.506980   \n",
       "22        NeuralNetTorch_BAG_L1         NaN -17.592214   \n",
       "23              LightGBM_BAG_L2         NaN -17.677431   \n",
       "24       RandomForestMSE_BAG_L2         NaN -18.049925   \n",
       "25            LightGBMXT_BAG_L1         NaN -18.137322   \n",
       "26              CatBoost_BAG_L1         NaN -18.314984   \n",
       "27               XGBoost_BAG_L1         NaN -18.586261   \n",
       "28              LightGBM_BAG_L1         NaN -18.628670   \n",
       "29       NeuralNetFastAI_BAG_L1         NaN -19.285642   \n",
       "\n",
       "                eval_metric  pred_time_test  pred_time_val   fit_time  \\\n",
       "0   root_mean_squared_error        0.261975            NaN   5.976656   \n",
       "1   root_mean_squared_error        0.020360            NaN   0.613156   \n",
       "2   root_mean_squared_error        0.026905            NaN   1.073183   \n",
       "3   root_mean_squared_error        0.427677            NaN   9.061599   \n",
       "4   root_mean_squared_error        0.057180       0.111965   0.745788   \n",
       "5   root_mean_squared_error        0.061879       0.111965   0.745788   \n",
       "6   root_mean_squared_error        0.466024            NaN   8.879183   \n",
       "7   root_mean_squared_error        0.057920       0.110477   0.634167   \n",
       "8   root_mean_squared_error        0.058716       0.110477   0.634167   \n",
       "9   root_mean_squared_error        0.035028            NaN   0.896542   \n",
       "10  root_mean_squared_error        0.520418            NaN  11.033476   \n",
       "11  root_mean_squared_error        0.420932            NaN   8.716364   \n",
       "12  root_mean_squared_error        0.155318            NaN   3.499712   \n",
       "13  root_mean_squared_error        0.042751            NaN   0.497625   \n",
       "14  root_mean_squared_error        0.467423            NaN   8.937135   \n",
       "15  root_mean_squared_error        0.425257            NaN   9.737270   \n",
       "16  root_mean_squared_error        0.024496            NaN   0.979337   \n",
       "17  root_mean_squared_error             NaN       2.196870  29.720611   \n",
       "18  root_mean_squared_error             NaN       1.841475  26.576901   \n",
       "19  root_mean_squared_error             NaN       1.499218  16.601287   \n",
       "20  root_mean_squared_error             NaN       2.051022  24.323691   \n",
       "21  root_mean_squared_error             NaN       1.895018  22.293772   \n",
       "22  root_mean_squared_error             NaN       1.163003  10.544702   \n",
       "23  root_mean_squared_error             NaN       1.834052  22.562593   \n",
       "24  root_mean_squared_error             NaN       1.909316  22.351723   \n",
       "25  root_mean_squared_error             NaN       0.031854   0.943573   \n",
       "26  root_mean_squared_error             NaN       0.258069   3.784321   \n",
       "27  root_mean_squared_error             NaN       0.045983   1.319098   \n",
       "28  root_mean_squared_error             NaN       0.032298   0.984569   \n",
       "29  root_mean_squared_error             NaN       0.074093   3.769294   \n",
       "\n",
       "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0                  0.001974                     NaN           0.009593   \n",
       "1                  0.020360                     NaN           0.613156   \n",
       "2                  0.026905                     NaN           1.073183   \n",
       "3                  0.027284                     NaN           0.735244   \n",
       "4                  0.057180                0.111965           0.745788   \n",
       "5                  0.061879                0.111965           0.745788   \n",
       "6                  0.065631                0.099574           0.552829   \n",
       "7                  0.057920                0.110477           0.634167   \n",
       "8                  0.058716                0.110477           0.634167   \n",
       "9                  0.035028                     NaN           0.896542   \n",
       "10                 0.002246                     NaN           0.008133   \n",
       "11                 0.020538                     NaN           0.390009   \n",
       "12                 0.155318                     NaN           3.499712   \n",
       "13                 0.042751                     NaN           0.497625   \n",
       "14                 0.067029                0.113872           0.610780   \n",
       "15                 0.024864                     NaN           1.410915   \n",
       "16                 0.024496                     NaN           0.979337   \n",
       "17                      NaN                0.000243           0.008133   \n",
       "18                      NaN                0.046031           4.835958   \n",
       "19                      NaN                0.000309           0.009593   \n",
       "20                      NaN                0.255578           2.582748   \n",
       "21                      NaN                0.099574           0.552829   \n",
       "22                      NaN                1.163003          10.544702   \n",
       "23                      NaN                0.038608           0.821650   \n",
       "24                      NaN                0.113872           0.610780   \n",
       "25                      NaN                0.031854           0.943573   \n",
       "26                      NaN                0.258069           3.784321   \n",
       "27                      NaN                0.045983           1.319098   \n",
       "28                      NaN                0.032298           0.984569   \n",
       "29                      NaN                0.074093           3.769294   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             2       True         24  \n",
       "1             1       True         17  \n",
       "2             1       True         19  \n",
       "3             2       True         28  \n",
       "4             1       True         20  \n",
       "5             1       True          5  \n",
       "6             2       True         29  \n",
       "7             1       True          3  \n",
       "8             1       True         18  \n",
       "9             1       True         16  \n",
       "10            3       True         30  \n",
       "11            2       True         26  \n",
       "12            1       True         23  \n",
       "13            1       True         22  \n",
       "14            2       True         27  \n",
       "15            2       True         25  \n",
       "16            1       True         21  \n",
       "17            3      False         15  \n",
       "18            2      False         10  \n",
       "19            2      False          9  \n",
       "20            2      False         13  \n",
       "21            2      False         14  \n",
       "22            1      False          8  \n",
       "23            2      False         11  \n",
       "24            2      False         12  \n",
       "25            1      False          1  \n",
       "26            1      False          4  \n",
       "27            1      False          7  \n",
       "28            1      False          2  \n",
       "29            1      False          6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047]\n",
      "Computing feature importance via permutation shuffling for 0 features using 87 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best performing model: WeightedEnsemble_L2_FULL\n",
      "\n",
      "Feature importance not available for this model type\n"
     ]
    }
   ],
   "source": [
    "# Show the leaderboard of all models trained by AutoGluon\n",
    "leaderboard = predictor.leaderboard(test_data)\n",
    "display(leaderboard)\n",
    "\n",
    "# Get information about the best model\n",
    "best_model = leaderboard.iloc[0][\"model\"]\n",
    "print(f\"\\nBest performing model: {best_model}\")\n",
    "\n",
    "# Get feature importance if available (works for some model types)\n",
    "try:\n",
    "    importance = predictor.feature_importance(test_data)\n",
    "    print(\"\\nTop 10 most important features:\")\n",
    "    display(importance.head(10))\n",
    "except:\n",
    "    print(\"\\nFeature importance not available for this model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've learned how to:\n",
    "\n",
    "1. Use AutoML to automatically build machine learning models\n",
    "2. Prepare a materials science dataset for machine learning\n",
    "3. Train multiple models with minimal code using AutoGluon\n",
    "4. Evaluate model performance using standard metrics\n",
    "5. Interpret model results and compare different algorithms\n",
    "\n",
    "AutoML is a powerful approach for quickly developing baseline models and can often achieve competitive performance with minimal effort.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **Hyperparameter Exploration**: Try different time limits (e.g., 30s, 120s, 300s) and presets (e.g., 'medium_quality', 'best_quality') and compare the results.\n",
    "\n",
    "2. **Feature Engineering**: Apply some scaling to the features (MinMax, RobustScaler from scikit-learn) before feeding them into AutoGluon and see if it improves performance.\n",
    "\n",
    "3. **Cross-Validation**: Modify the code to use cross-validation instead of a single train-test split.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
